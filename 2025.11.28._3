library(dplyr)
library(caret)
library(randomForest)
library(xgboost)

rdata <- read.csv("product.csv", fileEncoding="EUC-KR")

# -----------------
# 1. 데이터 전처리
# -----------------

# RandomForest와 XGBoost 모두 0/1 숫자 변수가 필요
rdata$성별 <- ifelse(rdata$성별 == "남자", 1, 0)

data <- rdata %>% 
  select(쇼핑액1월, 쇼핑액2월, 쇼핑액3월, 대표제품이름, 소득, 성별)

set.seed(123)
idx <- sample(1:nrow(data), nrow(data)*0.8)
train <- data[idx,]
test <- data[-idx,]

# -----------------
# 2. RandomForest
# -----------------

train$성별 <- as.factor(train$성별)
test$성별  <- as.factor(test$성별)

md <- randomForest(성별 ~ ., data=train, ntree=300)
pred <- predict(md, newdata=test)

cm <- confusionMatrix(pred, test$성별, mode="everything")

precision <- cm$byClass["Pos Pred Value"]
recall    <- cm$byClass["Sensitivity"]

f1 <- 2*precision*recall/(precision + recall)
f1 <- round(f1, 3)

print(f1)

# -----------------
# 3. XGBoost
# -----------------

# 성별을 다시 numeric으로
train$성별 <- as.numeric(as.character(train$성별))
test$성별  <- as.numeric(as.character(test$성별))

train_x <- model.matrix(성별 ~ . -1, data=train)
test_x  <- model.matrix(성별 ~ . -1, data=test)

dtrain <- xgb.DMatrix(train_x, label=train$성별)
dtest  <- xgb.DMatrix(test_x,  label=test$성별)

params <- list(
  objective = "binary:logistic",
  eval_metric = "logloss",
  eta = 0.1,
  max_depth = 4,
  nthread = 2
)

md_tune <- xgb.train(
  param=params,
  data=dtrain,
  nrounds=100
)

pred_tune <- predict(md_tune, dtest)
pred_tune <- ifelse(pred_tune > 0.5, 1, 0)

cm_tune <- confusionMatrix(
  factor(pred_tune, levels=c(0,1)),
  factor(test$성별, levels=c(0,1)),
  mode="everything"
)

precision_tune <- cm_tune$byClass["Pos Pred Value"]
recall_tune    <- cm_tune$byClass["Sensitivity"]

f1_tune <- 2*precision_tune*recall_tune/(precision_tune + recall_tune)
f1_tune <- round(f1_tune, 3)

print(f1_tune)
